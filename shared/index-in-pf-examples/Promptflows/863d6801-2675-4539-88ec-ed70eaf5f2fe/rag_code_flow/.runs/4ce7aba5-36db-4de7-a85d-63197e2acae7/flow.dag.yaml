inputs:
  question:
    type: string
    default: Generate a list of the indexed documents and summarize in bullets it's main points
    is_chat_input: true
  chat_history:
    type: list
    default:
    - inputs:
        question: List a summary regarding the kind of content on the documents indexed
      outputs:
        output: 'The documents indexed contain internal information about B3, a company that offers data products and services for the capital market. They have built their products and go-to-market strategy both organically and through acquisitions. They have a mature platform with effective data search and filter tools, high analytical capacity, and a dedicated sales force. Their main applications include queries tool for deep searches and market analysis, management and flow of leads for tracking opportunities, distribution of opportunities in maps for identifying geographic patterns, and a complete market overview through a dashboard for competition and target market analysis. Additionally, B3 offers credit services, loss prevention products, market data, indices, capital markets analytics, and sales & marketing solutions. (Source: azureml://locations/eastus2/workspaces/9d181c34-3537-4e69-9501-15ce8c725467/data/newdocs/versions/1/20231002 D&AB3 Microsoft.pdf)'
    - inputs:
        question: Responda com o conteúdo dos documentos indexados, responda sobre análises de mercado sobre fundos de investimentos. Crie uma lista dos fundos e subitens das suas características
      outputs:
        output: I apologize, but I cannot generate a list of funds and their characteristics as the documents indexed do not provide information specifically about market analysis of investment funds. The documents mainly contain information about the terms, definitions, and financial indicators related to specific funds, such as CSHG Renda Urbana FII and CSHG Logística FII. If you have any specific questions about these funds or any other topic within the documents, I'll be happy to assist you.
    is_chat_input: false
    is_chat_history: true
outputs:
  output:
    type: string
    reference: ${answer_the_question_with_context.output}
    evaluation_only: false
    is_chat_output: true
nodes:
- name: modify_query_with_history
  type: llm
  source:
    type: code
    path: modify_query_with_history.jinja2
  inputs:
    deployment_name: "gpt-35-turbo-16k-120k-tokens-default"
    temperature: 1
    top_p: 1
    stop: ""
    max_tokens: 0
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: ""
    chat_history: "${inputs.chat_history}"
    question: "${flow.question}"
  api: chat
  provider: AzureOpenAI
  connection: Default_AzureOpenAI
  module: promptflow.tools.aoai
  aggregation: false
- name: embed_the_question
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: "Default_AzureOpenAI"
    deployment_name: "embedding-test-chat"
    input: "${modify_query_with_history.output}"
  aggregation: false
- name: search_question_from_indexed_docs
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.vector_index_lookup.VectorIndexLookup.search
  inputs:
    path: "azureml://subscriptions/90a714cc-9046-4198-95fd-cddaf8e146d6/resourcegroups/rg-aiDemoProject/providers/Microsoft.MachineLearningServices/workspaces/New-AI-DemoProject/data/blue-plane-5n5chd4w1v/versions/1"
    query: "${embed_the_question.output}"
    top_k: 2
  aggregation: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: "${search_question_from_indexed_docs.output}"
  aggregation: false
- name: answer_the_question_with_context
  type: llm
  source:
    type: code
    path: answer_the_question_with_context.jinja2
  inputs:
    deployment_name: "gpt-35-turbo-16k-120k-tokens-default"
    temperature: 0
    top_p: 1
    stop: ""
    max_tokens: 1000
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: ""
    prompt_text: "${Prompt_variants.output}"
  api: chat
  provider: AzureOpenAI
  connection: Default_AzureOpenAI
  module: promptflow.tools.aoai
  aggregation: false
- name: Prompt_variants
  type: prompt
  source:
    type: code
    path: Prompt_variants__Variant_0.jinja2
  inputs:
    chat_history: "${flow.chat_history}"
    contexts: "${generate_prompt_context.output}"
    question: "${flow.question}"
  aggregation: false
environment:
  python_requirements_txt: requirements.txt
