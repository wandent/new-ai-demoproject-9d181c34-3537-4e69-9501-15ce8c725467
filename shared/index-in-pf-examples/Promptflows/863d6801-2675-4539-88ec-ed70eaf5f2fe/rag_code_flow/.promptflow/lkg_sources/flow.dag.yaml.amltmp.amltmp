inputs:
  question:
    type: string
    default: List a summary regarding the kind of content on the documents indexed
    is_chat_input: true
  chat_history:
    type: list
    default:
    - inputs:
        question: List a summary regarding the kind of content on the documents indexed
      outputs:
        output: "The documents indexed contain internal information about B3, a company
          that offers data products and services for the capital market. They
          have built their products and go-to-market strategy both organically
          and through acquisitions. They have a mature platform with effective
          data search and filter tools, high analytical capacity, and a
          dedicated sales force. Their main applications include queries tool
          for deep searches and market analysis, management and flow of leads
          for tracking opportunities, distribution of opportunities in maps for
          identifying geographic patterns, and a complete market overview
          through a dashboard for competition and target market analysis.
          Additionally, B3 offers credit services, loss prevention products,
          market data, indices, capital markets analytics, and sales & marketing
          solutions. (Source:
          azureml://locations/eastus2/workspaces/9d181c34-3537-4e69-9501-15ce8c\
          725467/data/newdocs/versions/1/20231002 D&AB3 Microsoft.pdf)"
    is_chat_input: false
    is_chat_history: true
outputs:
  output:
    type: string
    reference: ${answer_the_question_with_context.output}
    evaluation_only: false
    is_chat_output: true
nodes:
- name: modify_query_with_history
  type: llm
  source:
    type: code
    path: modify_query_with_history.jinja2
  inputs:
    deployment_name: gpt-35-turbo-16k-120k-tokens-default
    temperature: 1
    top_p: 1
    stop: ""
    max_tokens: 0
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: ""
    chat_history: ${inputs.chat_history}
    question: ${flow.question}
  provider: AzureOpenAI
  connection: Default_AzureOpenAI
  api: chat
  module: promptflow.tools.aoai
  use_variants: false
- name: embed_the_question
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: Default_AzureOpenAI
    deployment_name: embedding-test-chat
    input: ${modify_query_with_history.output}
  aggregation: false
  use_variants: false
- name: search_question_from_indexed_docs
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.vector_index_lookup.VectorIndexLookup.search
  inputs:
    path: azureml://subscriptions/90a714cc-9046-4198-95fd-cddaf8e146d6/resourcegroups/rg-aiDemoProject/providers/Microsoft.MachineLearningServices/workspaces/New-AI-DemoProject/data/blue-plane-5n5chd4w1v/versions/1
    query: ${embed_the_question.output}
    top_k: 2
  aggregation: false
  use_variants: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: ${search_question_from_indexed_docs.output}
  aggregation: false
  use_variants: false
- name: Prompt_variants
  use_variants: true
- name: answer_the_question_with_context
  type: llm
  source:
    type: code
    path: answer_the_question_with_context.jinja2
  inputs:
    deployment_name: gpt-35-turbo-16k-120k-tokens-default
    temperature: 0
    top_p: 1
    stop: ""
    max_tokens: 1000
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: ""
    prompt_text: ${Prompt_variants.output}
  provider: AzureOpenAI
  connection: Default_AzureOpenAI
  api: chat
  module: promptflow.tools.aoai
  aggregation: false
  use_variants: false
node_variants:
  Prompt_variants:
    default_variant_id: Variant_0
    variants:
      Variant_0:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__Variant_0.jinja2
          inputs:
            chat_history: ${flow.chat_history}
            contexts: ${generate_prompt_context.output}
            question: ${flow.question}
          aggregation: false
      Variant_1:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__Variant_1.jinja2
          inputs:
            chat_history: ${flow.chat_history}
            contexts: ${generate_prompt_context.output}
            question: ${flow.question}
          aggregation: false
      Variant_2:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__Variant_2.jinja2
          inputs:
            chat_history: ${flow.chat_history}
            contexts: ${generate_prompt_context.output}
            question: ${flow.question}
          aggregation: false
environment:
  python_requirements_txt: requirements.txt
